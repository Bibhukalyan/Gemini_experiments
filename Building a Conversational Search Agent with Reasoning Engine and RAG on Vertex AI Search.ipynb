{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be98c9c9-d664-49df-9395-bd07dd57f29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloudpickle==3.0.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pydantic==2.7.4\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "Collecting langchain-google-community\n",
      "  Downloading langchain_google_community-2.0.4-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-cloud-discoveryengine\n",
      "  Downloading google_cloud_discoveryengine-0.13.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.159.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: google-cloud-aiplatform[langchain,reasoningengine] in ./.local/lib/python3.10/site-packages (1.77.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==2.7.4) (0.7.0)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic==2.7.4)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic==2.7.4) (4.12.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in ./.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[langchain,reasoningengine]) (2.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (2.37.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (3.27.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (2.0.6)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (0.16)\n",
      "Collecting google-cloud-trace<2 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading google_cloud_trace-1.15.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform[langchain,reasoningengine]) (1.27.0)\n",
      "Collecting opentelemetry-exporter-gcp-trace<2 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading opentelemetry_exporter_gcp_trace-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain<0.4,>=0.1.16 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain_core-0.3.30-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-google-vertexai<3 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain_google_vertexai-2.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langgraph<0.3,>=0.2.45 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langgraph-0.2.64-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting openinference-instrumentation-langchain<0.2,>=0.1.19 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading openinference_instrumentation_langchain-0.1.29-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain-google-community) (2.4.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.62.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-community) (1.68.1)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-google-community)\n",
      "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client) (3.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[langchain,reasoningengine]) (1.66.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[langchain,reasoningengine]) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[langchain,reasoningengine]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[langchain,reasoningengine]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[langchain,reasoningengine]) (4.9)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[langchain,reasoningengine]) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[langchain,reasoningengine]) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform[langchain,reasoningengine]) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform[langchain,reasoningengine]) (1.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (3.11.11)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (1.26.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4->google-cloud-aiplatform[langchain,reasoningengine]) (1.33)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting httpx<0.29.0,>=0.28.0 (from langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-vertexai<3 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain_google_vertexai-2.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-google-vertexai<3 (from google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langchain_google_vertexai-2.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_vertexai-2.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading langchain_google_vertexai-2.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph<0.3,>=0.2.45->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langgraph_checkpoint-2.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph<0.3,>=0.2.45->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting openinference-instrumentation>=0.1.17 (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading openinference_instrumentation-0.1.20-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.9 (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: opentelemetry-api in /opt/conda/lib/python3.10/site-packages (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (1.27.0)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /opt/conda/lib/python3.10/site-packages (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (0.48b0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (1.17.0)\n",
      "Collecting opentelemetry-resourcedetector-gcp==1.*,>=1.5.0dev0 (from opentelemetry-exporter-gcp-trace<2->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading opentelemetry_resourcedetector_gcp-1.8.0a0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api->openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api->openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (8.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine]) (4.7.0)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine]) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4->google-cloud-aiplatform[langchain,reasoningengine]) (3.0.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph<0.3,>=0.2.45->google-cloud-aiplatform[langchain,reasoningengine]) (1.1.0)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph<0.3,>=0.2.45->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[langchain,reasoningengine]) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-google-community) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[langchain,reasoningengine]) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4,>=0.1.16->google-cloud-aiplatform[langchain,reasoningengine]) (3.1.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-instrumentation to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine])\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (75.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api->openinference-instrumentation-langchain<0.2,>=0.1.19->google-cloud-aiplatform[langchain,reasoningengine]) (3.21.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-google-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->langchain-google-vertexai<3->google-cloud-aiplatform[langchain,reasoningengine]) (1.2.2)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_google_community-2.0.4-py3-none-any.whl (84 kB)\n",
      "Downloading google_cloud_discoveryengine-0.13.5-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_python_client-2.159.0-py2.py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_trace-1.15.0-py2.py3-none-any.whl (100 kB)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.30-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_google_vertexai-2.0.7-py3-none-any.whl (89 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading langgraph-0.2.64-py3-none-any.whl (142 kB)\n",
      "Downloading openinference_instrumentation_langchain-0.1.29-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_gcp_trace-1.8.0-py3-none-any.whl (13 kB)\n",
      "Downloading opentelemetry_resourcedetector_gcp-1.8.0a0-py3-none-any.whl (20 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Downloading langgraph_checkpoint-2.0.10-py3-none-any.whl (37 kB)\n",
      "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
      "Downloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Downloading openinference_instrumentation-0.1.20-py3-none-any.whl (14 kB)\n",
      "Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
      "Downloading orjson-3.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: pydantic-core, orjson, openinference-semantic-conventions, mypy-extensions, marshmallow, httpx-sse, httpcore, cloudpickle, async-timeout, typing-inspect, requests-toolbelt, pydantic, httpx, pydantic-settings, opentelemetry-instrumentation, langsmith, langgraph-sdk, dataclasses-json, langchain-core, google-api-python-client, opentelemetry-resourcedetector-gcp, openinference-instrumentation, langgraph-checkpoint, langchain-text-splitters, google-cloud-trace, google-cloud-storage, google-cloud-discoveryengine, opentelemetry-exporter-gcp-trace, openinference-instrumentation-langchain, langgraph, langchain, langchain-google-vertexai, langchain-community, langchain-google-community\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.0\n",
      "    Uninstalling cloudpickle-3.1.0:\n",
      "      Successfully uninstalled cloudpickle-3.1.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.4\n",
      "    Uninstalling pydantic-2.10.4:\n",
      "      Successfully uninstalled pydantic-2.10.4\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.8.0\n",
      "    Uninstalling google-api-python-client-1.8.0:\n",
      "      Successfully uninstalled google-api-python-client-1.8.0\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.159.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 cloudpickle-3.0.0 dataclasses-json-0.6.7 google-api-python-client-2.159.0 google-cloud-discoveryengine-0.13.5 google-cloud-storage-2.19.0 google-cloud-trace-1.15.0 httpcore-1.0.7 httpx-0.27.2 httpx-sse-0.4.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.30 langchain-google-community-2.0.4 langchain-google-vertexai-2.0.7 langchain-text-splitters-0.3.5 langgraph-0.2.64 langgraph-checkpoint-2.0.10 langgraph-sdk-0.1.51 langsmith-0.2.11 marshmallow-3.25.1 mypy-extensions-1.0.0 openinference-instrumentation-0.1.20 openinference-instrumentation-langchain-0.1.29 openinference-semantic-conventions-0.1.12 opentelemetry-exporter-gcp-trace-1.8.0 opentelemetry-instrumentation-0.48b0 opentelemetry-resourcedetector-gcp-1.8.0a0 orjson-3.10.14 pydantic-2.7.4 pydantic-core-2.18.4 pydantic-settings-2.7.1 requests-toolbelt-1.0.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"google-cloud-aiplatform[langchain,reasoningengine]\" cloudpickle==3.0.0 pydantic==2.7.4 langchain-google-community google-cloud-discoveryengine google-api-python-client requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "734bc832-ec6f-4b30-8190-2fb07fd7827f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163b1bc4-7097-4e2c-8166-7a8ae90f5f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####Set Google Cloud project information and initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641d1aee-a8ae-4c7b-ba2d-03ce42bb87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-03-414f71a120f8\"  \n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://qwiklabs-gcp-03-414f71a120f8\"  \n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28863e1-0cb7-4eae-a5f7-6e4919a0604f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####Import libraries and define generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d56896-75d8-4834-a0ba-1f06b5da8c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.agents.format_scratchpad.tools import format_to_tool_messages\n",
    "from langchain_core import prompts\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from vertexai.preview import reasoning_engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f4c28f-063e-49da-9b38-45fdc0d3b541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-1.5-pro-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b4d343-aca3-4c43-8888-c50c746201d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIn this task, you'll create a Search App and Data Store within Vertex AI Search and index records from a movie data set.\\n\\nIn the Google Cloud Console, select Navigation menu > Agent Builder.\\n\\nRead and agree to the Terms of Service, then click Continue and activate the API.\\n\\nClick +CREATE APP.\\n\\nOn the Create App page, select the Search app type, enter the following details and click on Continue.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Task 2. Create a Data Store in Vertex AI Search\n",
    "\"\"\"\n",
    "In this task, you'll create a Search App and Data Store within Vertex AI Search and index records from a movie data set.\n",
    "\n",
    "In the Google Cloud Console, select Navigation menu > Agent Builder.\n",
    "\n",
    "Read and agree to the Terms of Service, then click Continue and activate the API.\n",
    "\n",
    "Click +CREATE APP.\n",
    "\n",
    "On the Create App page, select the Search app type, enter the following details and click on Continue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c85190-557e-4afc-bfb1-598c67d2bc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_STORE_ID = \"cymbal-movie-data_1737189767070\"\n",
    "LOCATION_ID = \"global\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "342de503-4107-4460-a99e-9d0b4a1c5323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this task, construct a conversational AI agent equipped with reasoning abilities. The agent will utilize a tool function to interact with Vertex AI Search and leverage the Langchain Agent framework to combine the model, tools, and reasoning for effective user interaction.\\n\\nDefine Python functions as tools\\nThis component of the agent employs Python functions as tools, allowing the Gemini model to interact with external systems, databases, and document repositories. This enables the model to access the latest information and perform actions within these systems.\\n\\nDefine a function that sends a query to Vertex AI Search and returns relevant records from the previously created data store.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Task 3. Define and test your agent locally\n",
    "\"\"\"\n",
    "In this task, construct a conversational AI agent equipped with reasoning abilities. The agent will utilize a tool function to interact with Vertex AI Search and leverage the Langchain Agent framework to combine the model, tools, and reasoning for effective user interaction.\n",
    "\n",
    "Define Python functions as tools\n",
    "This component of the agent employs Python functions as tools, allowing the Gemini model to interact with external systems, databases, and document repositories. This enables the model to access the latest information and perform actions within these systems.\n",
    "\n",
    "Define a function that sends a query to Vertex AI Search and returns relevant records from the previously created data store.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7fe2f5c-b9ef-420b-a3d0-eaa77bebb3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_kaggle_movies(query: str) -> str:\n",
    "    \"\"\"Search across records in the Kaggle Movies data set.\"\"\"\n",
    "    from langchain_google_community import VertexAISearchRetriever\n",
    "\n",
    "    retriever = VertexAISearchRetriever(\n",
    "        project_id=PROJECT_ID,\n",
    "        data_store_id=DATA_STORE_ID,\n",
    "        location_id=LOCATION_ID,\n",
    "        engine_data_type=1,\n",
    "        max_documents=10,\n",
    "    )\n",
    "\n",
    "    result = str(retriever.invoke(query))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd530a59-62de-4549-ac0b-31e770e3d67d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_google_community/vertex_ai_search.py:364: UserWarning: Beta features are configured but beta=False. The following beta features will be ignored:['custom_embedding_ratio']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_kaggle_movies(\"Harry Potter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c00bc701-4306-4e7f-9343-06739a7a7e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    \"history\": lambda x: x[\"history\"],\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": (lambda x: format_to_tool_messages(x[\"intermediate_steps\"])),\n",
    "} | prompts.ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        prompts.MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        prompts.MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize session history\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b93711a-523c-4c42-b989-432be1cad689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    chat_history=get_session_history,\n",
    "    model_kwargs={\"temperature\": 0},\n",
    "    tools=[search_kaggle_movies],\n",
    "    agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6deb52c-519f-4721-b0c1-cb4fcd0e8d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_google_community/vertex_ai_search.py:364: UserWarning: Beta features are configured but beta=False. The following beta features will be ignored:['custom_embedding_ratio']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I was unable to find any sci-fi movies from the 1990s in the Kaggle Movies dataset. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    input=\"List some sci-fi movies from the 1990s\",\n",
    "    config={\"configurable\": {\"session_id\": \"demo\"}},\n",
    ")\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6644b5cd-695f-4cbe-8344-e7ce15c9a1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = reasoning_engines.LangchainAgent(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    chat_history=get_session_history,\n",
    "    model_kwargs={\"temperature\": 0},\n",
    "    tools=[search_kaggle_movies],\n",
    "    agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee71d41-5f64-4175-b979-460a3268423f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bucket qwiklabs-gcp-03-414f71a120f8 in location='us-central1'\n",
      "Writing to gs://qwiklabs-gcp-03-414f71a120f8/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://qwiklabs-gcp-03-414f71a120f8/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://qwiklabs-gcp-03-414f71a120f8/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/580799819376/locations/us-central1/reasoningEngines/6016580403748405248/operations/3117839939828449280\n"
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[langchain,reasoningengine]\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic==2.7.4\",\n",
    "        \"langchain-google-community\",\n",
    "        \"google-cloud-discoveryengine\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e45bc-b668-4492-9abd-a90cdfe49d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = discovery.build(\"cloudresourcemanager\", \"v1\")\n",
    "request = service.projects().get(projectId=PROJECT_ID)\n",
    "response = request.execute()\n",
    "project_number = response[\"projectNumber\"]\n",
    "project_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067227c4-894c-44f5-8707-2262da0f5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
    "    --member=serviceAccount:service-{project_number}@gcp-sa-aiplatform-re.iam.gserviceaccount.com \\\n",
    "    --role=roles/discoveryengine.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb33c69-c92b-44d3-ae47-cd2075e490a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = remote_agent.query(\n",
    "    input=\"List some sci-fi movies from the 1990s\",\n",
    "    config={\"configurable\": {\"session_id\": \"demo\"}},\n",
    ")\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5224e-cfd9-4dcb-84c2-e9ae6450f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = remote_agent.query(\n",
    "    input=\"Who are the actors in The Matrix?\",\n",
    "    config={\"configurable\": {\"session_id\": \"demo\"}},\n",
    ")\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e7e5c-c12d-4eb2-a1ae-5cc6d4298a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = remote_agent.query(\n",
    "    input=\"Are those actors in any other movies?\",\n",
    "    config={\"configurable\": {\"session_id\": \"demo\"}},\n",
    ")\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
